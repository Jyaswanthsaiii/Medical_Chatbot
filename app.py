import os
from PyPDF2 import PdfReader
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import CharacterTextSplitter
from langchain.chains.question_answering import load_qa_chain
from langchain_openai import OpenAI
from flask import Flask, render_template, request, make_response
from weasyprint import HTML
from PyPDF2 import PdfMerger

# Set your OpenAI API key (Replace with your actual key)
os.environ["OPENAI_API_KEY"] = "KEY"

# Initialize Flask app
app = Flask(__name__)

# Function to extract text from a PDF file
def process_pdf(pdf_path):
    """
    This function reads a PDF file and extracts all the text content from it.

    Args:
        pdf_path (str): Path to the PDF file.

    Returns:
        str: The extracted text content from the PDF.
    """
    reader = PdfReader(pdf_path)
    raw_text = ''
    for page in reader.pages:
        text = page.extract_text()
        if text:
            raw_text += text
    return raw_text

# Initialize Flask routes
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/submit', methods=['POST'])
def submit():
    # Extract form data
    full_name = request.form['full_name']
    age = request.form['age']
    gender = request.form['gender']
    symptoms = request.form['symptoms']
    
    # Formulate final input for processing
    final_input = "The given conversation acts as the \'communicationEnglish\'. By matching those, only return the appropriate list of symptoms and the name of the disease that was found after analysis. If either the input is wrong or the data is insufficient, just tell that \'Data is insufficient\'"
    final_input += symptoms

    # Process the user query and get the answer
    response = process_query(final_input)
    
    # Render template with response
    return render_template('report_form.html', full_name=full_name, age=age, gender=gender, symptoms=response)

@app.route('/convert_to_pdf', methods=['POST'])
def convert_to_pdf():
    # Extract form data
    full_name = request.form['full_name']
    age = request.form['age']
    gender = request.form['gender']
    symptoms = request.form['symptoms']
    
    # Process the symptoms to generate a response
    response = symptoms
    
    # Render PDF template
    rendered_template = render_template('report.html', full_name=full_name, age=age, gender=gender, symptoms=response)
    
    # Convert HTML to PDF
    pdf = HTML(string=rendered_template).write_pdf()
    
    # Save the generated PDF
    with open("report.pdf", "wb") as f:
        f.write(pdf)
    
    # Merge existing PDF with generated PDF
    merger = PdfMerger()
    pdfs = ['HomePage.pdf', 'report.pdf']
    
    for pdf_file in pdfs:
        merger.append(pdf_file)
    
    # Write the merged PDF
    merger.write("merged_report.pdf")
    merger.close()
    
    # Prepare PDF response
    with open("merged_report.pdf", "rb") as f:
        merged_pdf = f.read()
    
    response = make_response(merged_pdf)
    response.headers['Content-Type'] = 'application/pdf'
    response.headers['Content-Disposition'] = f'attachment; filename="{full_name}_report.pdf"'
    
    return response

# Main function to process user query
def process_query(query):
    """
    This function takes a user query, searches for similar text chunks in the FAISS index,
    and then uses the question answering model to answer the query based on those relevant chunks.

    Args:
        query (str): The user's question.

    Returns:
        str: The answer generated by the question answering model.
    """
    # Search for similar text chunks in the FAISS index
    docs = docsearch.similarity_search(query)
    
    # Use the question answering model to answer the query based on relevant chunks
    result = chain.run(input_documents=docs, question=query)
    return result

if __name__ == '__main__':
    # Directory containing the PDF files
    data_dir = "./data"

    # Variable to store all extracted text
    final_text = ''

    # Iterate through all files in the data directory
    for filename in os.listdir(data_dir):
        if filename.endswith(".pdf"):
            full_path = os.path.join(data_dir, filename)
            # Call process_pdf to extract text from each PDF
            final_text += process_pdf(full_path)

    # Split the extracted text into smaller chunks for processing
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len,
    )
    texts = text_splitter.split_text(final_text)

    # Initialize OpenAI embeddings for creating vector representations of text
    embeddings = OpenAIEmbeddings()

    # Create FAISS index to efficiently search similar text chunks
    docsearch = FAISS.from_texts(texts, embeddings)

    # Load a question answering model (here, OpenAI) to answer questions based on the text
    chain = load_qa_chain(OpenAI(), chain_type="stuff")

    # Run Flask app
    app.run(debug=True)
